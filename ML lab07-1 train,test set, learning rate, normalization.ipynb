{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate를 변경하면서 cost를 비교한다\n",
    "\n",
    "train/test set으로 나누어 학습시키고 accuracy를 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f6edd8615048>:44: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n",
      "0 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "1 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "2 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "3 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "4 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "5 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "6 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "7 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "8 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "9 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "10 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "11 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "12 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "13 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "14 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "15 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "16 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "17 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "18 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "19 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "20 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "21 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "22 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "23 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "24 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "25 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "26 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "27 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "28 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "29 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "30 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "31 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "32 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "33 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "34 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "35 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "36 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "37 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "38 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "39 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "40 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "41 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "42 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "43 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "44 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "45 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "46 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "47 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "48 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "49 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "50 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "51 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "52 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "53 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "54 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "55 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "56 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "57 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "58 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "59 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "60 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "61 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "62 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "63 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "64 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "65 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "66 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "67 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "68 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "69 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "70 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "71 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "72 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "73 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "74 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "75 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "76 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "77 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "78 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "79 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "80 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "81 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "82 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "83 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "84 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "85 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "86 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "87 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "88 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "89 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "90 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "91 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "92 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "93 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "94 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "95 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "96 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "97 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "98 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "99 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "100 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "101 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "102 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "103 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "104 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "105 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "106 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "107 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "108 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "109 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "110 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "111 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "112 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "113 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "114 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "115 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "116 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "117 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "118 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "119 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "120 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "121 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "122 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "123 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "124 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "125 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "126 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "127 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "128 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "129 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "130 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "131 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "132 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "133 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "134 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "135 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "136 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "137 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "138 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "139 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "140 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "141 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "142 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "143 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "144 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "145 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "146 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "147 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "148 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "149 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "150 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "151 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "152 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "153 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "154 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "155 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "156 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "157 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "158 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "159 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "160 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "161 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "162 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "163 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "164 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "165 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "166 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "167 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "168 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "169 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "170 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "171 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "172 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "173 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "174 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "175 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "176 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "177 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "178 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "179 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "180 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "181 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "182 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "183 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "184 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "185 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "186 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "187 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "188 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "189 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "190 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "191 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "192 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "193 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "194 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "195 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "196 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "197 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "198 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "199 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "200 8.727206 [[-0.7115535   0.62098664  0.5261439 ]\n",
      " [ 0.4442905  -0.38458702  1.3592359 ]\n",
      " [-0.40581986  0.68094885  1.3594123 ]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=1e-10).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.arg_max(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run(\n",
    "            [cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate를 너무 크게주면 cost값이 줄어들지를 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-normalized inputs를 학습시키면 결과값이 NaN이 나온다 (값들의 기준이 너무 차이났기 때문)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xy = MinMaxScaler(xy) 라는 함수로 정규화를 시킨 후 학습시키면된다\n",
    "\n",
    "0~1 사이의 값으로 스케일링한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MinMaxScaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
      " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "0 Cost:  4.1314335 \n",
      "Prediction:\n",
      " [[-0.6903733]\n",
      " [-1.2411041]\n",
      " [-1.4032648]\n",
      " [-1.5672076]\n",
      " [-1.4444995]\n",
      " [-1.5791197]\n",
      " [-2.01866  ]\n",
      " [-2.222594 ]]\n",
      "1 Cost:  4.1311445 \n",
      "Prediction:\n",
      " [[-0.6902783]\n",
      " [-1.2410091]\n",
      " [-1.4031849]\n",
      " [-1.5671449]\n",
      " [-1.4444263]\n",
      " [-1.5790486]\n",
      " [-2.0186098]\n",
      " [-2.2225437]]\n",
      "2 Cost:  4.1308556 \n",
      "Prediction:\n",
      " [[-0.6901833]\n",
      " [-1.2409141]\n",
      " [-1.403105 ]\n",
      " [-1.5670822]\n",
      " [-1.4443529]\n",
      " [-1.5789775]\n",
      " [-2.0185595]\n",
      " [-2.2224934]]\n",
      "3 Cost:  4.1305666 \n",
      "Prediction:\n",
      " [[-0.6900883]\n",
      " [-1.240819 ]\n",
      " [-1.4030252]\n",
      " [-1.5670195]\n",
      " [-1.4442797]\n",
      " [-1.5789063]\n",
      " [-2.0185094]\n",
      " [-2.222443 ]]\n",
      "4 Cost:  4.1302776 \n",
      "Prediction:\n",
      " [[-0.68999326]\n",
      " [-1.2407238 ]\n",
      " [-1.4029453 ]\n",
      " [-1.5669568 ]\n",
      " [-1.4442064 ]\n",
      " [-1.5788352 ]\n",
      " [-2.018459  ]\n",
      " [-2.2223928 ]]\n",
      "5 Cost:  4.1299887 \n",
      "Prediction:\n",
      " [[-0.68989825]\n",
      " [-1.2406288 ]\n",
      " [-1.4028654 ]\n",
      " [-1.5668942 ]\n",
      " [-1.444133  ]\n",
      " [-1.5787642 ]\n",
      " [-2.0184088 ]\n",
      " [-2.2223425 ]]\n",
      "6 Cost:  4.1297007 \n",
      "Prediction:\n",
      " [[-0.68980324]\n",
      " [-1.2405336 ]\n",
      " [-1.4027857 ]\n",
      " [-1.5668315 ]\n",
      " [-1.4440598 ]\n",
      " [-1.5786932 ]\n",
      " [-2.0183587 ]\n",
      " [-2.2222924 ]]\n",
      "7 Cost:  4.129411 \n",
      "Prediction:\n",
      " [[-0.68970823]\n",
      " [-1.2404387 ]\n",
      " [-1.4027057 ]\n",
      " [-1.5667688 ]\n",
      " [-1.4439864 ]\n",
      " [-1.5786221 ]\n",
      " [-2.0183084 ]\n",
      " [-2.222242  ]]\n",
      "8 Cost:  4.1291223 \n",
      "Prediction:\n",
      " [[-0.6896132]\n",
      " [-1.2403436]\n",
      " [-1.4026258]\n",
      " [-1.5667061]\n",
      " [-1.4439132]\n",
      " [-1.5785509]\n",
      " [-2.018258 ]\n",
      " [-2.2221918]]\n",
      "9 Cost:  4.128834 \n",
      "Prediction:\n",
      " [[-0.6895182]\n",
      " [-1.2402484]\n",
      " [-1.402546 ]\n",
      " [-1.5666435]\n",
      " [-1.4438398]\n",
      " [-1.5784799]\n",
      " [-2.018208 ]\n",
      " [-2.2221415]]\n",
      "10 Cost:  4.1285453 \n",
      "Prediction:\n",
      " [[-0.6894232]\n",
      " [-1.2401534]\n",
      " [-1.4024662]\n",
      " [-1.5665807]\n",
      " [-1.4437666]\n",
      " [-1.5784088]\n",
      " [-2.0181577]\n",
      " [-2.2220912]]\n",
      "11 Cost:  4.128256 \n",
      "Prediction:\n",
      " [[-0.6893282]\n",
      " [-1.2400584]\n",
      " [-1.4023863]\n",
      " [-1.566518 ]\n",
      " [-1.4436932]\n",
      " [-1.5783377]\n",
      " [-2.0181077]\n",
      " [-2.222041 ]]\n",
      "12 Cost:  4.1279674 \n",
      "Prediction:\n",
      " [[-0.6892332]\n",
      " [-1.2399633]\n",
      " [-1.4023066]\n",
      " [-1.5664554]\n",
      " [-1.44362  ]\n",
      " [-1.5782666]\n",
      " [-2.0180573]\n",
      " [-2.2219906]]\n",
      "13 Cost:  4.1276784 \n",
      "Prediction:\n",
      " [[-0.6891382]\n",
      " [-1.2398682]\n",
      " [-1.4022266]\n",
      " [-1.5663927]\n",
      " [-1.4435467]\n",
      " [-1.5781956]\n",
      " [-2.018007 ]\n",
      " [-2.2219403]]\n",
      "14 Cost:  4.12739 \n",
      "Prediction:\n",
      " [[-0.68904316]\n",
      " [-1.2397732 ]\n",
      " [-1.4021467 ]\n",
      " [-1.56633   ]\n",
      " [-1.4434733 ]\n",
      " [-1.5781244 ]\n",
      " [-2.017957  ]\n",
      " [-2.2218902 ]]\n",
      "15 Cost:  4.1271014 \n",
      "Prediction:\n",
      " [[-0.68894815]\n",
      " [-1.239678  ]\n",
      " [-1.402067  ]\n",
      " [-1.5662673 ]\n",
      " [-1.4434    ]\n",
      " [-1.5780535 ]\n",
      " [-2.0179067 ]\n",
      " [-2.22184   ]]\n",
      "16 Cost:  4.1268125 \n",
      "Prediction:\n",
      " [[-0.68885314]\n",
      " [-1.239583  ]\n",
      " [-1.4019871 ]\n",
      " [-1.5662045 ]\n",
      " [-1.4433267 ]\n",
      " [-1.5779823 ]\n",
      " [-2.0178564 ]\n",
      " [-2.2217896 ]]\n",
      "17 Cost:  4.126524 \n",
      "Prediction:\n",
      " [[-0.68875813]\n",
      " [-1.239488  ]\n",
      " [-1.4019072 ]\n",
      " [-1.5661418 ]\n",
      " [-1.4432535 ]\n",
      " [-1.5779113 ]\n",
      " [-2.0178063 ]\n",
      " [-2.2217393 ]]\n",
      "18 Cost:  4.126235 \n",
      "Prediction:\n",
      " [[-0.6886631]\n",
      " [-1.2393928]\n",
      " [-1.4018273]\n",
      " [-1.5660791]\n",
      " [-1.4431801]\n",
      " [-1.5778401]\n",
      " [-2.017756 ]\n",
      " [-2.221689 ]]\n",
      "19 Cost:  4.125946 \n",
      "Prediction:\n",
      " [[-0.6885681]\n",
      " [-1.2392979]\n",
      " [-1.4017475]\n",
      " [-1.5660164]\n",
      " [-1.4431068]\n",
      " [-1.577769 ]\n",
      " [-2.017706 ]\n",
      " [-2.2216387]]\n",
      "20 Cost:  4.1256576 \n",
      "Prediction:\n",
      " [[-0.6884731]\n",
      " [-1.2392027]\n",
      " [-1.4016676]\n",
      " [-1.5659537]\n",
      " [-1.4430335]\n",
      " [-1.577698 ]\n",
      " [-2.0176556]\n",
      " [-2.2215886]]\n",
      "21 Cost:  4.125369 \n",
      "Prediction:\n",
      " [[-0.6883781]\n",
      " [-1.2391076]\n",
      " [-1.4015878]\n",
      " [-1.565891 ]\n",
      " [-1.4429603]\n",
      " [-1.577627 ]\n",
      " [-2.0176053]\n",
      " [-2.2215383]]\n",
      "22 Cost:  4.12508 \n",
      "Prediction:\n",
      " [[-0.6882831]\n",
      " [-1.2390125]\n",
      " [-1.4015079]\n",
      " [-1.5658283]\n",
      " [-1.442887 ]\n",
      " [-1.5775559]\n",
      " [-2.0175552]\n",
      " [-2.221488 ]]\n",
      "23 Cost:  4.1247916 \n",
      "Prediction:\n",
      " [[-0.6881881]\n",
      " [-1.2389176]\n",
      " [-1.4014281]\n",
      " [-1.5657656]\n",
      " [-1.4428136]\n",
      " [-1.5774847]\n",
      " [-2.017505 ]\n",
      " [-2.2214377]]\n",
      "24 Cost:  4.1245027 \n",
      "Prediction:\n",
      " [[-0.68809307]\n",
      " [-1.2388225 ]\n",
      " [-1.4013482 ]\n",
      " [-1.565703  ]\n",
      " [-1.4427403 ]\n",
      " [-1.5774136 ]\n",
      " [-2.0174546 ]\n",
      " [-2.2213874 ]]\n",
      "25 Cost:  4.124214 \n",
      "Prediction:\n",
      " [[-0.68799806]\n",
      " [-1.2387273 ]\n",
      " [-1.4012684 ]\n",
      " [-1.5656403 ]\n",
      " [-1.442667  ]\n",
      " [-1.5773425 ]\n",
      " [-2.0174046 ]\n",
      " [-2.221337  ]]\n",
      "26 Cost:  4.1239257 \n",
      "Prediction:\n",
      " [[-0.68790305]\n",
      " [-1.2386323 ]\n",
      " [-1.4011886 ]\n",
      " [-1.5655776 ]\n",
      " [-1.4425938 ]\n",
      " [-1.5772715 ]\n",
      " [-2.0173542 ]\n",
      " [-2.2212868 ]]\n",
      "27 Cost:  4.123637 \n",
      "Prediction:\n",
      " [[-0.68780804]\n",
      " [-1.2385372 ]\n",
      " [-1.4011087 ]\n",
      " [-1.565515  ]\n",
      " [-1.4425204 ]\n",
      " [-1.5772004 ]\n",
      " [-2.017304  ]\n",
      " [-2.2212367 ]]\n",
      "28 Cost:  4.1233487 \n",
      "Prediction:\n",
      " [[-0.687713 ]\n",
      " [-1.2384422]\n",
      " [-1.4010289]\n",
      " [-1.5654523]\n",
      " [-1.4424472]\n",
      " [-1.5771294]\n",
      " [-2.0172539]\n",
      " [-2.2211864]]\n",
      "29 Cost:  4.12306 \n",
      "Prediction:\n",
      " [[-0.687618 ]\n",
      " [-1.2383472]\n",
      " [-1.400949 ]\n",
      " [-1.5653896]\n",
      " [-1.4423738]\n",
      " [-1.5770583]\n",
      " [-2.0172036]\n",
      " [-2.221136 ]]\n",
      "30 Cost:  4.1227713 \n",
      "Prediction:\n",
      " [[-0.687523 ]\n",
      " [-1.238252 ]\n",
      " [-1.4008691]\n",
      " [-1.5653269]\n",
      " [-1.4423006]\n",
      " [-1.5769873]\n",
      " [-2.0171533]\n",
      " [-2.2210858]]\n",
      "31 Cost:  4.1224833 \n",
      "Prediction:\n",
      " [[-0.687428 ]\n",
      " [-1.238157 ]\n",
      " [-1.4007893]\n",
      " [-1.5652642]\n",
      " [-1.4422272]\n",
      " [-1.5769161]\n",
      " [-2.0171032]\n",
      " [-2.2210355]]\n",
      "32 Cost:  4.1221943 \n",
      "Prediction:\n",
      " [[-0.6873331]\n",
      " [-1.238062 ]\n",
      " [-1.4007095]\n",
      " [-1.5652015]\n",
      " [-1.4421539]\n",
      " [-1.5768452]\n",
      " [-2.017053 ]\n",
      " [-2.2209854]]\n",
      "33 Cost:  4.1219063 \n",
      "Prediction:\n",
      " [[-0.6872382]\n",
      " [-1.237967 ]\n",
      " [-1.4006296]\n",
      " [-1.5651388]\n",
      " [-1.4420807]\n",
      " [-1.576774 ]\n",
      " [-2.0170028]\n",
      " [-2.220935 ]]\n",
      "34 Cost:  4.1216173 \n",
      "Prediction:\n",
      " [[-0.6871432]\n",
      " [-1.2378719]\n",
      " [-1.4005499]\n",
      " [-1.5650761]\n",
      " [-1.4420074]\n",
      " [-1.5767028]\n",
      " [-2.0169525]\n",
      " [-2.2208848]]\n",
      "35 Cost:  4.1213293 \n",
      "Prediction:\n",
      " [[-0.6870482]\n",
      " [-1.237777 ]\n",
      " [-1.40047  ]\n",
      " [-1.5650135]\n",
      " [-1.4419342]\n",
      " [-1.576632 ]\n",
      " [-2.0169022]\n",
      " [-2.2208345]]\n",
      "36 Cost:  4.121041 \n",
      "Prediction:\n",
      " [[-0.6869533]\n",
      " [-1.237682 ]\n",
      " [-1.4003901]\n",
      " [-1.5649508]\n",
      " [-1.4418609]\n",
      " [-1.5765609]\n",
      " [-2.0168521]\n",
      " [-2.2207842]]\n",
      "37 Cost:  4.1207523 \n",
      "Prediction:\n",
      " [[-0.6868584]\n",
      " [-1.237587 ]\n",
      " [-1.4003104]\n",
      " [-1.5648882]\n",
      " [-1.4417876]\n",
      " [-1.5764898]\n",
      " [-2.0168018]\n",
      " [-2.2207341]]\n",
      "38 Cost:  4.1204643 \n",
      "Prediction:\n",
      " [[-0.6867634]\n",
      " [-1.2374918]\n",
      " [-1.4002306]\n",
      " [-1.5648255]\n",
      " [-1.4417143]\n",
      " [-1.5764188]\n",
      " [-2.0167518]\n",
      " [-2.2206838]]\n",
      "39 Cost:  4.120176 \n",
      "Prediction:\n",
      " [[-0.6866684]\n",
      " [-1.237397 ]\n",
      " [-1.4001508]\n",
      " [-1.5647628]\n",
      " [-1.4416411]\n",
      " [-1.5763476]\n",
      " [-2.0167015]\n",
      " [-2.2206335]]\n",
      "40 Cost:  4.1198874 \n",
      "Prediction:\n",
      " [[-0.6865735]\n",
      " [-1.2373018]\n",
      " [-1.4000709]\n",
      " [-1.5647001]\n",
      " [-1.4415679]\n",
      " [-1.5762767]\n",
      " [-2.0166512]\n",
      " [-2.2205832]]\n",
      "41 Cost:  4.1195993 \n",
      "Prediction:\n",
      " [[-0.6864786]\n",
      " [-1.2372069]\n",
      " [-1.3999912]\n",
      " [-1.5646374]\n",
      " [-1.4414945]\n",
      " [-1.5762056]\n",
      " [-2.016601 ]\n",
      " [-2.220533 ]]\n",
      "42 Cost:  4.119311 \n",
      "Prediction:\n",
      " [[-0.6863837]\n",
      " [-1.2371119]\n",
      " [-1.3999113]\n",
      " [-1.5645748]\n",
      " [-1.4414213]\n",
      " [-1.5761346]\n",
      " [-2.0165508]\n",
      " [-2.2204826]]\n",
      "43 Cost:  4.1190224 \n",
      "Prediction:\n",
      " [[-0.68628883]\n",
      " [-1.2370169 ]\n",
      " [-1.3998315 ]\n",
      " [-1.5645123 ]\n",
      " [-1.4413481 ]\n",
      " [-1.5760635 ]\n",
      " [-2.0165005 ]\n",
      " [-2.2204325 ]]\n",
      "44 Cost:  4.1187344 \n",
      "Prediction:\n",
      " [[-0.68619394]\n",
      " [-1.236922  ]\n",
      " [-1.3997518 ]\n",
      " [-1.5644495 ]\n",
      " [-1.4412749 ]\n",
      " [-1.5759926 ]\n",
      " [-2.0164504 ]\n",
      " [-2.2203822 ]]\n",
      "45 Cost:  4.118447 \n",
      "Prediction:\n",
      " [[-0.68609905]\n",
      " [-1.2368271 ]\n",
      " [-1.399672  ]\n",
      " [-1.5643868 ]\n",
      " [-1.4412016 ]\n",
      " [-1.5759215 ]\n",
      " [-2.0164    ]\n",
      " [-2.220332  ]]\n",
      "46 Cost:  4.1181583 \n",
      "Prediction:\n",
      " [[-0.68600416]\n",
      " [-1.236732  ]\n",
      " [-1.3995922 ]\n",
      " [-1.5643243 ]\n",
      " [-1.4411283 ]\n",
      " [-1.5758505 ]\n",
      " [-2.01635   ]\n",
      " [-2.2202816 ]]\n",
      "47 Cost:  4.1178703 \n",
      "Prediction:\n",
      " [[-0.6859093]\n",
      " [-1.2366371]\n",
      " [-1.3995125]\n",
      " [-1.5642616]\n",
      " [-1.441055 ]\n",
      " [-1.5757794]\n",
      " [-2.0162997]\n",
      " [-2.2202315]]\n",
      "48 Cost:  4.117582 \n",
      "Prediction:\n",
      " [[-0.6858144]\n",
      " [-1.2365422]\n",
      " [-1.3994327]\n",
      " [-1.564199 ]\n",
      " [-1.4409819]\n",
      " [-1.5757084]\n",
      " [-2.0162494]\n",
      " [-2.2201812]]\n",
      "49 Cost:  4.1172943 \n",
      "Prediction:\n",
      " [[-0.6857195]\n",
      " [-1.2364471]\n",
      " [-1.3993529]\n",
      " [-1.5641363]\n",
      " [-1.4409086]\n",
      " [-1.5756375]\n",
      " [-2.0161994]\n",
      " [-2.220131 ]]\n",
      "50 Cost:  4.117006 \n",
      "Prediction:\n",
      " [[-0.6856246]\n",
      " [-1.2363522]\n",
      " [-1.3992732]\n",
      " [-1.5640736]\n",
      " [-1.4408355]\n",
      " [-1.5755664]\n",
      " [-2.016149 ]\n",
      " [-2.2200806]]\n",
      "51 Cost:  4.1167173 \n",
      "Prediction:\n",
      " [[-0.6855297]\n",
      " [-1.2362572]\n",
      " [-1.3991933]\n",
      " [-1.564011 ]\n",
      " [-1.4407622]\n",
      " [-1.5754954]\n",
      " [-2.016099 ]\n",
      " [-2.2200303]]\n",
      "52 Cost:  4.1164293 \n",
      "Prediction:\n",
      " [[-0.6854348]\n",
      " [-1.2361622]\n",
      " [-1.3991135]\n",
      " [-1.5639483]\n",
      " [-1.4406888]\n",
      " [-1.5754243]\n",
      " [-2.0160487]\n",
      " [-2.2199802]]\n",
      "53 Cost:  4.1161413 \n",
      "Prediction:\n",
      " [[-0.6853399]\n",
      " [-1.2360673]\n",
      " [-1.3990338]\n",
      " [-1.5638857]\n",
      " [-1.4406157]\n",
      " [-1.5753534]\n",
      " [-2.0159984]\n",
      " [-2.21993  ]]\n",
      "54 Cost:  4.1158533 \n",
      "Prediction:\n",
      " [[-0.68524504]\n",
      " [-1.2359724 ]\n",
      " [-1.3989539 ]\n",
      " [-1.563823  ]\n",
      " [-1.4405425 ]\n",
      " [-1.5752823 ]\n",
      " [-2.0159483 ]\n",
      " [-2.2198796 ]]\n",
      "55 Cost:  4.1155653 \n",
      "Prediction:\n",
      " [[-0.68515015]\n",
      " [-1.2358773 ]\n",
      " [-1.3988743 ]\n",
      " [-1.5637603 ]\n",
      " [-1.4404693 ]\n",
      " [-1.5752113 ]\n",
      " [-2.015898  ]\n",
      " [-2.2198293 ]]\n",
      "56 Cost:  4.1152773 \n",
      "Prediction:\n",
      " [[-0.68505526]\n",
      " [-1.2357824 ]\n",
      " [-1.3987944 ]\n",
      " [-1.5636978 ]\n",
      " [-1.440396  ]\n",
      " [-1.5751402 ]\n",
      " [-2.015848  ]\n",
      " [-2.219779  ]]\n",
      "57 Cost:  4.1149893 \n",
      "Prediction:\n",
      " [[-0.68496037]\n",
      " [-1.2356875 ]\n",
      " [-1.3987147 ]\n",
      " [-1.5636351 ]\n",
      " [-1.4403226 ]\n",
      " [-1.5750692 ]\n",
      " [-2.0157976 ]\n",
      " [-2.219729  ]]\n",
      "58 Cost:  4.1147013 \n",
      "Prediction:\n",
      " [[-0.6848655]\n",
      " [-1.2355924]\n",
      " [-1.3986349]\n",
      " [-1.5635724]\n",
      " [-1.4402494]\n",
      " [-1.5749981]\n",
      " [-2.0157475]\n",
      " [-2.2196786]]\n",
      "59 Cost:  4.1144133 \n",
      "Prediction:\n",
      " [[-0.6847706]\n",
      " [-1.2354975]\n",
      " [-1.398555 ]\n",
      " [-1.5635098]\n",
      " [-1.4401762]\n",
      " [-1.5749272]\n",
      " [-2.0156972]\n",
      " [-2.2196283]]\n",
      "60 Cost:  4.1141253 \n",
      "Prediction:\n",
      " [[-0.6846757]\n",
      " [-1.2354026]\n",
      " [-1.3984753]\n",
      " [-1.5634471]\n",
      " [-1.440103 ]\n",
      " [-1.5748563]\n",
      " [-2.015647 ]\n",
      " [-2.219578 ]]\n",
      "61 Cost:  4.1138372 \n",
      "Prediction:\n",
      " [[-0.6845808]\n",
      " [-1.2353075]\n",
      " [-1.3983955]\n",
      " [-1.5633845]\n",
      " [-1.4400299]\n",
      " [-1.5747852]\n",
      " [-2.0155969]\n",
      " [-2.219528 ]]\n",
      "62 Cost:  4.113549 \n",
      "Prediction:\n",
      " [[-0.6844859]\n",
      " [-1.2352126]\n",
      " [-1.3983158]\n",
      " [-1.5633218]\n",
      " [-1.4399564]\n",
      " [-1.5747142]\n",
      " [-2.0155466]\n",
      " [-2.2194777]]\n",
      "63 Cost:  4.113261 \n",
      "Prediction:\n",
      " [[-0.684391 ]\n",
      " [-1.2351177]\n",
      " [-1.398236 ]\n",
      " [-1.5632591]\n",
      " [-1.4398832]\n",
      " [-1.5746431]\n",
      " [-2.0154965]\n",
      " [-2.2194273]]\n",
      "64 Cost:  4.112973 \n",
      "Prediction:\n",
      " [[-0.68429613]\n",
      " [-1.2350227 ]\n",
      " [-1.3981562 ]\n",
      " [-1.5631965 ]\n",
      " [-1.43981   ]\n",
      " [-1.5745721 ]\n",
      " [-2.0154462 ]\n",
      " [-2.219377  ]]\n",
      "65 Cost:  4.112685 \n",
      "Prediction:\n",
      " [[-0.68420124]\n",
      " [-1.2349277 ]\n",
      " [-1.3980764 ]\n",
      " [-1.563134  ]\n",
      " [-1.4397368 ]\n",
      " [-1.5745012 ]\n",
      " [-2.015396  ]\n",
      " [-2.2193267 ]]\n",
      "66 Cost:  4.1123977 \n",
      "Prediction:\n",
      " [[-0.68410635]\n",
      " [-1.2348328 ]\n",
      " [-1.3979967 ]\n",
      " [-1.5630713 ]\n",
      " [-1.4396635 ]\n",
      " [-1.5744301 ]\n",
      " [-2.0153458 ]\n",
      " [-2.2192767 ]]\n",
      "67 Cost:  4.112109 \n",
      "Prediction:\n",
      " [[-0.68401146]\n",
      " [-1.2347379 ]\n",
      " [-1.3979169 ]\n",
      " [-1.5630085 ]\n",
      " [-1.4395903 ]\n",
      " [-1.574359  ]\n",
      " [-2.0152955 ]\n",
      " [-2.2192264 ]]\n",
      "68 Cost:  4.1118217 \n",
      "Prediction:\n",
      " [[-0.68391657]\n",
      " [-1.2346427 ]\n",
      " [-1.3978372 ]\n",
      " [-1.5629458 ]\n",
      " [-1.4395171 ]\n",
      " [-1.574288  ]\n",
      " [-2.0152454 ]\n",
      " [-2.219176  ]]\n",
      "69 Cost:  4.1115336 \n",
      "Prediction:\n",
      " [[-0.6838217]\n",
      " [-1.2345479]\n",
      " [-1.3977573]\n",
      " [-1.5628834]\n",
      " [-1.4394438]\n",
      " [-1.5742171]\n",
      " [-2.0151951]\n",
      " [-2.2191257]]\n",
      "70 Cost:  4.111246 \n",
      "Prediction:\n",
      " [[-0.6837268]\n",
      " [-1.234453 ]\n",
      " [-1.3976775]\n",
      " [-1.5628207]\n",
      " [-1.4393706]\n",
      " [-1.574146 ]\n",
      " [-2.0151448]\n",
      " [-2.2190757]]\n",
      "71 Cost:  4.110958 \n",
      "Prediction:\n",
      " [[-0.6836319]\n",
      " [-1.234358 ]\n",
      " [-1.3975978]\n",
      " [-1.562758 ]\n",
      " [-1.4392974]\n",
      " [-1.574075 ]\n",
      " [-2.0150948]\n",
      " [-2.2190254]]\n",
      "72 Cost:  4.11067 \n",
      "Prediction:\n",
      " [[-0.683537 ]\n",
      " [-1.2342631]\n",
      " [-1.397518 ]\n",
      " [-1.5626954]\n",
      " [-1.4392242]\n",
      " [-1.5740039]\n",
      " [-2.0150445]\n",
      " [-2.218975 ]]\n",
      "73 Cost:  4.110382 \n",
      "Prediction:\n",
      " [[-0.6834421]\n",
      " [-1.2341682]\n",
      " [-1.3974383]\n",
      " [-1.5626327]\n",
      " [-1.439151 ]\n",
      " [-1.5739329]\n",
      " [-2.0149944]\n",
      " [-2.2189248]]\n",
      "74 Cost:  4.110094 \n",
      "Prediction:\n",
      " [[-0.6833472]\n",
      " [-1.2340732]\n",
      " [-1.3973584]\n",
      " [-1.56257  ]\n",
      " [-1.4390777]\n",
      " [-1.573862 ]\n",
      " [-2.014944 ]\n",
      " [-2.2188747]]\n",
      "75 Cost:  4.109807 \n",
      "Prediction:\n",
      " [[-0.68325233]\n",
      " [-1.2339783 ]\n",
      " [-1.3972788 ]\n",
      " [-1.5625074 ]\n",
      " [-1.4390044 ]\n",
      " [-1.573791  ]\n",
      " [-2.014894  ]\n",
      " [-2.2188244 ]]\n",
      "76 Cost:  4.10952 \n",
      "Prediction:\n",
      " [[-0.6831577]\n",
      " [-1.2338835]\n",
      " [-1.3971992]\n",
      " [-1.5624449]\n",
      " [-1.4389315]\n",
      " [-1.5737202]\n",
      " [-2.014844 ]\n",
      " [-2.2187743]]\n",
      "77 Cost:  4.109233 \n",
      "Prediction:\n",
      " [[-0.68306303]\n",
      " [-1.2337887 ]\n",
      " [-1.3971196 ]\n",
      " [-1.5623825 ]\n",
      " [-1.4388585 ]\n",
      " [-1.5736494 ]\n",
      " [-2.0147939 ]\n",
      " [-2.2187243 ]]\n",
      "78 Cost:  4.108946 \n",
      "Prediction:\n",
      " [[-0.6829684]\n",
      " [-1.2336941]\n",
      " [-1.3970401]\n",
      " [-1.5623202]\n",
      " [-1.4387856]\n",
      " [-1.5735786]\n",
      " [-2.014744 ]\n",
      " [-2.2186744]]\n",
      "79 Cost:  4.1086593 \n",
      "Prediction:\n",
      " [[-0.6828737]\n",
      " [-1.2335994]\n",
      " [-1.3969605]\n",
      " [-1.5622578]\n",
      " [-1.4387125]\n",
      " [-1.5735078]\n",
      " [-2.014694 ]\n",
      " [-2.2186244]]\n",
      "80 Cost:  4.1083727 \n",
      "Prediction:\n",
      " [[-0.6827791]\n",
      " [-1.2335045]\n",
      " [-1.3968811]\n",
      " [-1.5621953]\n",
      " [-1.4386394]\n",
      " [-1.573437 ]\n",
      " [-2.0146441]\n",
      " [-2.2185743]]\n",
      "81 Cost:  4.1080856 \n",
      "Prediction:\n",
      " [[-0.6826844]\n",
      " [-1.2334099]\n",
      " [-1.3968015]\n",
      " [-1.562133 ]\n",
      " [-1.4385664]\n",
      " [-1.5733663]\n",
      " [-2.014594 ]\n",
      " [-2.2185242]]\n",
      "82 Cost:  4.107799 \n",
      "Prediction:\n",
      " [[-0.68258977]\n",
      " [-1.2333152 ]\n",
      " [-1.396722  ]\n",
      " [-1.5620706 ]\n",
      " [-1.4384935 ]\n",
      " [-1.5732955 ]\n",
      " [-2.0145442 ]\n",
      " [-2.2184744 ]]\n",
      "83 Cost:  4.1075125 \n",
      "Prediction:\n",
      " [[-0.6824951]\n",
      " [-1.2332206]\n",
      " [-1.3966424]\n",
      " [-1.5620081]\n",
      " [-1.4384205]\n",
      " [-1.5732248]\n",
      " [-2.0144942]\n",
      " [-2.2184243]]\n",
      "84 Cost:  4.1072254 \n",
      "Prediction:\n",
      " [[-0.68240047]\n",
      " [-1.2331258 ]\n",
      " [-1.3965629 ]\n",
      " [-1.5619457 ]\n",
      " [-1.4383476 ]\n",
      " [-1.573154  ]\n",
      " [-2.014444  ]\n",
      " [-2.2183743 ]]\n",
      "85 Cost:  4.106939 \n",
      "Prediction:\n",
      " [[-0.6823058]\n",
      " [-1.2330312]\n",
      " [-1.3964834]\n",
      " [-1.5618833]\n",
      " [-1.4382745]\n",
      " [-1.5730832]\n",
      " [-2.0143943]\n",
      " [-2.2183242]]\n",
      "86 Cost:  4.106652 \n",
      "Prediction:\n",
      " [[-0.68221116]\n",
      " [-1.2329364 ]\n",
      " [-1.3964038 ]\n",
      " [-1.5618209 ]\n",
      " [-1.4382015 ]\n",
      " [-1.5730124 ]\n",
      " [-2.0143442 ]\n",
      " [-2.2182744 ]]\n",
      "87 Cost:  4.106365 \n",
      "Prediction:\n",
      " [[-0.6821165]\n",
      " [-1.2328417]\n",
      " [-1.3963244]\n",
      " [-1.5617585]\n",
      " [-1.4381285]\n",
      " [-1.5729415]\n",
      " [-2.0142944]\n",
      " [-2.2182243]]\n",
      "88 Cost:  4.106078 \n",
      "Prediction:\n",
      " [[-0.68202186]\n",
      " [-1.2327471 ]\n",
      " [-1.3962448 ]\n",
      " [-1.561696  ]\n",
      " [-1.4380555 ]\n",
      " [-1.5728709 ]\n",
      " [-2.0142443 ]\n",
      " [-2.2181742 ]]\n",
      "89 Cost:  4.1057916 \n",
      "Prediction:\n",
      " [[-0.6819272]\n",
      " [-1.2326522]\n",
      " [-1.3961653]\n",
      " [-1.5616336]\n",
      " [-1.4379826]\n",
      " [-1.5728002]\n",
      " [-2.0141945]\n",
      " [-2.2181242]]\n",
      "90 Cost:  4.1055055 \n",
      "Prediction:\n",
      " [[-0.68183255]\n",
      " [-1.2325575 ]\n",
      " [-1.3960857 ]\n",
      " [-1.5615712 ]\n",
      " [-1.4379096 ]\n",
      " [-1.5727293 ]\n",
      " [-2.0141444 ]\n",
      " [-2.2180743 ]]\n",
      "91 Cost:  4.1052184 \n",
      "Prediction:\n",
      " [[-0.6817379]\n",
      " [-1.2324629]\n",
      " [-1.3960062]\n",
      " [-1.5615089]\n",
      " [-1.4378365]\n",
      " [-1.5726585]\n",
      " [-2.0140944]\n",
      " [-2.2180243]]\n",
      "92 Cost:  4.104932 \n",
      "Prediction:\n",
      " [[-0.68164325]\n",
      " [-1.2323681 ]\n",
      " [-1.3959267 ]\n",
      " [-1.5614464 ]\n",
      " [-1.4377636 ]\n",
      " [-1.5725877 ]\n",
      " [-2.0140445 ]\n",
      " [-2.2179742 ]]\n",
      "93 Cost:  4.104645 \n",
      "Prediction:\n",
      " [[-0.6815486]\n",
      " [-1.2322733]\n",
      " [-1.3958471]\n",
      " [-1.561384 ]\n",
      " [-1.4376905]\n",
      " [-1.5725169]\n",
      " [-2.0139945]\n",
      " [-2.217924 ]]\n",
      "94 Cost:  4.1043587 \n",
      "Prediction:\n",
      " [[-0.68145394]\n",
      " [-1.2321788 ]\n",
      " [-1.3957677 ]\n",
      " [-1.5613216 ]\n",
      " [-1.4376175 ]\n",
      " [-1.5724461 ]\n",
      " [-2.0139446 ]\n",
      " [-2.2178743 ]]\n",
      "95 Cost:  4.104072 \n",
      "Prediction:\n",
      " [[-0.6813593]\n",
      " [-1.232084 ]\n",
      " [-1.395688 ]\n",
      " [-1.5612593]\n",
      " [-1.4375446]\n",
      " [-1.5723754]\n",
      " [-2.0138946]\n",
      " [-2.2178242]]\n",
      "96 Cost:  4.1037855 \n",
      "Prediction:\n",
      " [[-0.68126464]\n",
      " [-1.2319894 ]\n",
      " [-1.3956087 ]\n",
      " [-1.5611968 ]\n",
      " [-1.4374716 ]\n",
      " [-1.5723047 ]\n",
      " [-2.0138447 ]\n",
      " [-2.2177742 ]]\n",
      "97 Cost:  4.1034985 \n",
      "Prediction:\n",
      " [[-0.68117  ]\n",
      " [-1.2318947]\n",
      " [-1.395529 ]\n",
      " [-1.5611343]\n",
      " [-1.4373986]\n",
      " [-1.5722339]\n",
      " [-2.0137947]\n",
      " [-2.2177243]]\n",
      "98 Cost:  4.1032124 \n",
      "Prediction:\n",
      " [[-0.68107533]\n",
      " [-1.2317998 ]\n",
      " [-1.3954496 ]\n",
      " [-1.561072  ]\n",
      " [-1.4373256 ]\n",
      " [-1.5721631 ]\n",
      " [-2.0137446 ]\n",
      " [-2.2176743 ]]\n",
      "99 Cost:  4.1029253 \n",
      "Prediction:\n",
      " [[-0.6809807]\n",
      " [-1.2317052]\n",
      " [-1.39537  ]\n",
      " [-1.5610095]\n",
      " [-1.4372526]\n",
      " [-1.5720923]\n",
      " [-2.0136948]\n",
      " [-2.2176242]]\n",
      "100 Cost:  4.1026387 \n",
      "Prediction:\n",
      " [[-0.68088603]\n",
      " [-1.2316105 ]\n",
      " [-1.3952905 ]\n",
      " [-1.5609472 ]\n",
      " [-1.4371796 ]\n",
      " [-1.5720215 ]\n",
      " [-2.0136447 ]\n",
      " [-2.2175741 ]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "# 가장중요한 부분\n",
    "# very important. It does not work without it.\n",
    "xy = MinMaxScaler(xy)\n",
    "print(xy)\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
